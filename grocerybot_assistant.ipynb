{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erNS8DBy9LZW"
      },
      "source": [
        "# GroceryBot, a grocery and recipe assistant - RAG + ReAct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe7OuYuGkLKF"
      },
      "source": [
        "### Authenticating your notebook environment\n",
        "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
        "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Gx2SAZkLKF"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxH62gFHCFPj"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1z48EbXTZhc"
      },
      "source": [
        "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM8_uoOR9pGS"
      },
      "outputs": [],
      "source": [
        "# import vertexai\n",
        "\n",
        "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
        "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHhdpnGMCCuh"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pprint\n",
        "from typing import Any, Iterator, List\n",
        "\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import Document\n",
        "from langchain.tools import tool\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.vectorstores.base import VectorStoreRetriever\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmZ1xwIo9lzU"
      },
      "source": [
        "### Initialize models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVpPcvsrkzCk"
      },
      "outputs": [],
      "source": [
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=256,\n",
        "    temperature=0,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        ")\n",
        "\n",
        "embedding = VertexAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx1DhGMexbdx"
      },
      "source": [
        "# Create the Recipe & Product retrievers\n",
        "\n",
        "The objective is to leverage information from closed-domain databases in order to provide more context to the LLM. To do so, create two retrievers in Langchain, capable of interacting with the two local vector databases: one for the product items, and another for the recipe items.\n",
        "\n",
        "**As a one off process**, every product and recipe item will be converted into an embedding and ingested into the relevant vector database.\n",
        "\n",
        "**At retrieval time**, the query (e.g. lasagne) will be converted into an embedding, and a vector similarity search will be performed to find the closest items to the query (e.g. lasagne al forno, vegetarian lasagne).\n",
        "\n",
        "To power these two databases, a set of dummy recipes and products generated using [Vertex AI Generative AI models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#foundation_models) is used.\n",
        "\n",
        "To load this data in the VectorStore, the [Langchain TextLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html) is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-pNxat75XND"
      },
      "source": [
        "First, fetch the dummy data on products and recipes from a public Cloud Storage bucket and store it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yP6GQhgV5Nz",
        "outputId": "0dcc0c1b-a38d-482d-b0bd-68a85b1a5e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://github-repo/use-cases/grocery_bot/products/classic_carrots.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/angus_beef_lean_mince.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/baby_plum_tomatoes.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/cherry_vine_tomatoes.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/classic_tomatoes.txt... \n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/large_onions.txt...     \n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/chocolate_bar.txt...    \n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/premium_plum_tomatoes.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/premium_red_tomatoes.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/chocolate_cake.txt...   \n",
            "Copying gs://github-repo/use-cases/grocery_bot/products/sandwich_selection.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/recipes/lasagne.txt...           \n",
            "Copying gs://github-repo/use-cases/grocery_bot/recipes/chicken_scallopini_with_asparagus.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/recipes/steak_and_peanut_salad.txt...\n",
            "Copying gs://github-repo/use-cases/grocery_bot/recipes/vegetarian_lasagne.txt...\n",
            "/ [15/15 files][ 17.1 KiB/ 17.1 KiB] 100% Done                                  \n",
            "Operation completed over 15 objects/17.1 KiB.                                    \n"
          ]
        }
      ],
      "source": [
        "!gsutil -m cp -r \"gs://github-repo/use-cases/grocery_bot/*\" ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ8G9k4M5gaM"
      },
      "source": [
        "Defining set of functions to enable the creation of the two vector databases, one for products, and one for recipes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezemXH4zxaX-"
      },
      "outputs": [],
      "source": [
        "def chunks(lst: List[Any], n: int) -> Iterator[List[Any]]:\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\n",
        "\n",
        "    Args:\n",
        "        lst: The list to be chunked.\n",
        "        n: The size of each chunk.\n",
        "\n",
        "    Yields:\n",
        "        A list of the next n elements from lst.\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i : i + n]\n",
        "\n",
        "\n",
        "def load_docs_from_directory(dir_path: str) -> List[Document]:\n",
        "    \"\"\"Loads a series of docs from a directory.\n",
        "\n",
        "    Args:\n",
        "      dir_path: The path to the directory containing the docs.\n",
        "\n",
        "    Returns:\n",
        "      A list of the docs in the directory.\n",
        "    \"\"\"\n",
        "\n",
        "    docs = []\n",
        "    for file_path in glob.glob(dir_path):\n",
        "        loader = TextLoader(file_path)\n",
        "        docs = docs + loader.load()\n",
        "    return docs\n",
        "\n",
        "\n",
        "def create_retriever(top_k_results: int, dir_path: str) -> VectorStoreRetriever:\n",
        "    \"\"\"Create a recipe retriever from a list of top results and a list of web pages.\n",
        "\n",
        "    Args:\n",
        "        top_k_results: number of results to return when retrieving\n",
        "        dir_path: List of web pages.\n",
        "\n",
        "    Returns:\n",
        "        A recipe retriever.\n",
        "    \"\"\"\n",
        "\n",
        "    BATCH_SIZE_EMBEDDINGS = 5\n",
        "    docs = load_docs_from_directory(dir_path=dir_path)\n",
        "    doc_chunk = chunks(docs, BATCH_SIZE_EMBEDDINGS)\n",
        "    for index, chunk in tqdm(enumerate(doc_chunk)):\n",
        "        if index == 0:\n",
        "            db = FAISS.from_documents(chunk, embedding)\n",
        "        else:\n",
        "            db.add_documents(chunk)\n",
        "\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": top_k_results})\n",
        "    return retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsjaRY6Y55yD"
      },
      "source": [
        "Creating the Vector DBs.\n",
        "Each Vector DB will provide a retriever instance, a Python object that, given a query, will provide a list of documents matching that query.\n",
        "\n",
        "Vector Databases:\n",
        "- `recipe_retriever`: to retrieve a set of recipes matching the query\n",
        "- `product_retriever`: to retrieve a set of products matching the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYb9WWvCKpxl",
        "outputId": "2da77f60-f777-4e03-9805-79127c984ff5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  1.54it/s]\n",
            "3it [00:00,  4.83it/s]\n"
          ]
        }
      ],
      "source": [
        "recipe_retriever = create_retriever(top_k_results=2, dir_path=\"./recipes/*\")\n",
        "product_retriever = create_retriever(top_k_results=5, dir_path=\"./products/*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzPr73OM6uDY"
      },
      "source": [
        "Testing the retrievers. For example if you ask `recipe_retriever` to find \"lasagne recipes\" you should see the two closest recipes matching the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGazDy8d54Hq",
        "outputId": "69f7c6e9-e4b8-4852-b274-3dd4eaa13a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'source': './recipes/lasagne.txt'},\n",
            " {'source': './recipes/vegetarian_lasagne.txt'}]\n"
          ]
        }
      ],
      "source": [
        "docs = recipe_retriever.get_relevant_documents(\"Any lasagne recipes?\")\n",
        "pprint.pprint([doc.metadata for doc in docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRVqmDHd5Vwb",
        "outputId": "d4d822ed-70f1-449f-90e8-28238a0939e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'source': './products/classic_tomatoes.txt'},\n",
            " {'source': './products/premium_plum_tomatoes.txt'},\n",
            " {'source': './products/baby_plum_tomatoes.txt'},\n",
            " {'source': './products/cherry_vine_tomatoes.txt'},\n",
            " {'source': './products/premium_red_tomatoes.txt'}]\n"
          ]
        }
      ],
      "source": [
        "docs = product_retriever.get_relevant_documents(\"Any Tomatoes?\")\n",
        "pprint.pprint([doc.metadata for doc in docs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f6193c"
      },
      "source": [
        "## Agent\n",
        "\n",
        "To create a Langchain Agent, which will be implemented using a ReAct-like approach.\n",
        "\n",
        "An Agent has access to a suite of tools, which you can think of as Python functions that can potentially do anything you equip it with. What makes the Agent setup unique is its ability to **autonomously** decide which tool to call and in which order, based on the user input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4IPCkA26CDV"
      },
      "source": [
        "## 1. Agent tools\n",
        "\n",
        "The first thing that needs to be created are the tools the agent will use. For each tool, it's critical to provide a good description of what the tool does, as it will be used by the agent to perform actions.\n",
        "\n",
        "\n",
        "Some of the tools have the parameter `return_direct=True` set in the decorator. This will ensure that the outputs of the tool won't be postprocessed by the LLM and will return directly to the user.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEwhy5WH9Bg_"
      },
      "source": [
        "Creating the two tools required to leverage the two retriever objects defined previously, `recipe_retriever` and `product_retriever`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMsssnT66aNC"
      },
      "outputs": [],
      "source": [
        "@tool(return_direct=True)\n",
        "def retrieve_recipes(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Searches the recipe catalog to find recipes for the query.\n",
        "    Return the output without processing further.\n",
        "    \"\"\"\n",
        "    docs = recipe_retriever.get_relevant_documents(query)\n",
        "\n",
        "    return (\n",
        "        f\"Select the recipe you would like to explore further about {query}: [START CALLBACK FRONTEND] \"\n",
        "        + str([doc.metadata for doc in docs])\n",
        "        + \" [END CALLBACK FRONTEND]\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5mo3KEj2j9Y"
      },
      "outputs": [],
      "source": [
        "@tool(return_direct=True)\n",
        "def retrieve_products(query: str) -> str:\n",
        "    \"\"\"Searches the product catalog to find products for the query.\n",
        "    Use it when the user asks for the products available for a specific item. For example `Can you show me which onions I can buy?`\n",
        "    \"\"\"\n",
        "    docs = product_retriever.get_relevant_documents(query)\n",
        "    return (\n",
        "        f\"I found these products about {query}:  [START CALLBACK FRONTEND] \"\n",
        "        + str([doc.metadata for doc in docs])\n",
        "        + \" [END CALLBACK FRONTEND]\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9LplS-w9haF"
      },
      "source": [
        "Define `recipe_selector`, a tool that will be used by the Agent to capture the action of the user selecting a recipe. The path of the recipe is used as an identifier of that recipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok1ryRoL_9WL"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def recipe_selector(path: str) -> str:\n",
        "    \"\"\"\n",
        "    Use this when the user selects a recipe.\n",
        "    You will need to respond to the user telling what are the options once a recipe is selected.\n",
        "    You can explain what are the ingredients of the recipe, show you the cooking instructions or suggest you which products to buy from the catalog!\n",
        "    \"\"\"\n",
        "    return \"Great choice! I can explain what are the ingredients of the recipe, show you the cooking instructions or suggest you which products to buy from the catalog!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhA4epiL9x00"
      },
      "source": [
        "The fourth tool allows the agent to find the details of a recipe given the path of the recipe. It will return as an observation the ingredients and the instructions for a given recipe. The agent will then use this information to respond to a specific query made by the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHjVjzo49T11"
      },
      "outputs": [],
      "source": [
        "docs = load_docs_from_directory(\"./recipes/*\")\n",
        "recipes_detail = {doc.metadata[\"source\"]: doc.page_content for doc in docs}\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_recipe_detail(path: str) -> str:\n",
        "    \"\"\"\n",
        "    Use it to find more information for a specific recipe, such as the ingredients or the cooking steps.\n",
        "    Use this to find what are the ingredients for a recipe or the cooking steps.\n",
        "\n",
        "    Example output:\n",
        "    Ingredients:\n",
        "\n",
        "    * 1 pound lasagna noodles\n",
        "    * 1 pound ground beef\n",
        "    * 1/2 cup chopped onion\n",
        "    * 2 cloves garlic, minced\n",
        "    * 2 (28 ounce) cans crushed tomatoes\n",
        "    * 1 (15 ounce) can tomato sauce\n",
        "    * 1 teaspoon dried oregano\n",
        "\n",
        "    Would you like me to show you the suggested products from the catalogue?\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return recipes_detail[path]\n",
        "    except KeyError:\n",
        "        return \"Could not find the details for this recipe\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-6mlDAT-bPZ"
      },
      "source": [
        "Finally, define a tool that allows the agent to find the best products for a specific recipe. In this project, this information is hardcoded in a dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqQ0FqtwyCai"
      },
      "outputs": [],
      "source": [
        "@tool(return_direct=True)\n",
        "def get_suggested_products_for_recipe(recipe_path: str) -> str:\n",
        "    \"\"\"Use this only if the user would like to buy certain products connected to a specific recipe example 'Can you give me the products I can buy for the lasagne?'\",\n",
        "\n",
        "    Args:\n",
        "        recipe_path: The recipe path.\n",
        "\n",
        "    Returns:\n",
        "        A list of products the user might want to buy.\n",
        "    \"\"\"\n",
        "    recipe_to_product_mapping = {\n",
        "        \"./recipes/lasagne.txt\": [\n",
        "            \"./products/angus_beef_lean_mince.txt\",\n",
        "            \"./products/large_onions.txt\",\n",
        "            \"./products/classic_carrots.txt\",\n",
        "            \"./products/classic_tomatoes.txt\",\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return (\n",
        "        \"These are some suggested ingredients for your recipe [START CALLBACK FRONTEND] \"\n",
        "        + str(recipe_to_product_mapping[recipe_path])\n",
        "        + \" [END CALLBACK FRONTEND]\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujl9NCfROjOv"
      },
      "source": [
        "## Creating the agent\n",
        "\n",
        "The agent is provided a memory so to allow a conversation.\n",
        "\n",
        "The agent will be initialised with the type `CONVERSATIONAL_REACT_DESCRIPTION`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFM6pMPX3bax"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "memory.clear()\n",
        "\n",
        "tools = [\n",
        "    retrieve_recipes,\n",
        "    retrieve_products,\n",
        "    get_recipe_detail,\n",
        "    get_suggested_products_for_recipe,\n",
        "    recipe_selector,\n",
        "]\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzAMcJe4YG0F"
      },
      "source": [
        "### Let's cook lasagne!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sv2Oi6XF84-",
        "outputId": "f2b3dd96-fa80-471e-d7e5-7cd765884b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: retrieve_recipes\n",
            "Action Input: lasagne\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSelect the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Select the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"I would like to cook some lasagne. What are the recipes available?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM5Am75a9dZE",
        "outputId": "3352c1e0-925d-493c-8545-77ee0d69ff2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: recipe_selector\n",
            "Action Input: ./recipes/lasagne.txt\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mGreat choice! I can explain what are the ingredients of the recipe, show you the cooking instructions or suggest you which products to buy from the catalog!\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Would you like me to show you the ingredients of the recipe?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Would you like me to show you the ingredients of the recipe?'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Selecting ./recipes/lasagne.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mabBRUecFX8",
        "outputId": "1336a36a-51e8-446e-f469-20f206a89ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: get_recipe_detail\n",
            "Action Input: ./recipes/lasagne.txt\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mIngredients:\n",
            "\n",
            "* 1 pound lasagna noodles\n",
            "* 1 pound ground beef\n",
            "* 1/2 cup chopped onion\n",
            "* 2 cloves garlic, minced\n",
            "* 2 (28 ounce) cans crushed tomatoes\n",
            "* 1 (15 ounce) can tomato sauce\n",
            "* 1 teaspoon dried oregano\n",
            "* 1/2 teaspoon salt\n",
            "* 1/4 teaspoon black pepper\n",
            "* 1/2 cup grated Parmesan cheese\n",
            "* 1/4 cup chopped fresh basil\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. Preheat oven to 375 degrees F (190 degrees C).\n",
            "2. In a large skillet, brown the ground beef, onion, and garlic over medium heat. Drain any excess fat.\n",
            "3. Stir in the crushed tomatoes, tomato sauce, oregano, salt, and pepper. Bring to a simmer and cook for 15 minutes, or until the sauce has thickened.\n",
            "4. In a 9x13 inch baking dish, layer half of the lasagna noodles, half of the meat sauce, 1/2 cup of Parmesan cheese, and 1/4 cup of basil. Repeat layers.\n",
            "5. Cover the baking dish with foil and bake for 30 minutes. Uncover and bake for an additional 15 minutes, or until the cheese is melted and bubbly.\n",
            "6. Let cool for 10 minutes before serving.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: Here are the ingredients for the lasagne recipe:\n",
            "\n",
            "* 1 pound lasagna noodles\n",
            "* 1 pound ground beef\n",
            "* 1/2 cup chopped onion\n",
            "* 2 cloves garlic, minced\n",
            "* 2 (28 ounce) cans crushed tomatoes\n",
            "* 1 (15 ounce) can tomato sauce\n",
            "* 1 teaspoon dried oregano\n",
            "* 1/2 teaspoon salt\n",
            "* 1/4 teaspoon black pepper\n",
            "* 1/2 cup grated Parmesan cheese\n",
            "* 1/4 cup chopped fresh basil\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Here are the ingredients for the lasagne recipe:\\n\\n* 1 pound lasagna noodles\\n* 1 pound ground beef\\n* 1/2 cup chopped onion\\n* 2 cloves garlic, minced\\n* 2 (28 ounce) cans crushed tomatoes\\n* 1 (15 ounce) can tomato sauce\\n* 1 teaspoon dried oregano\\n* 1/2 teaspoon salt\\n* 1/4 teaspoon black pepper\\n* 1/2 cup grated Parmesan cheese\\n* 1/4 cup chopped fresh basil'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Yes, can you give me the ingredients for that recipe?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUEIt7cdYBVg",
        "outputId": "26e30c5b-5b1c-4380-bc12-19b7389ae168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Sure, here are the cooking instructions for the lasagne recipe:\n",
            "\n",
            "1. Preheat oven to 375 degrees F (190 degrees C).\n",
            "2. In a large skillet, brown the ground beef over medium heat. Drain the grease.\n",
            "3. Add the onion and garlic to the skillet and cook until softened, about 5 minutes.\n",
            "4. Stir in the crushed tomatoes, tomato sauce, oregano, salt, and pepper. Bring to a boil, then reduce heat and simmer for 15 minutes.\n",
            "5. In a 9x13 inch baking dish, spread 1/3 of the meat sauce. Top with a layer of lasagna noodles. Repeat layers of meat sauce, noodles, and ricotta cheese until the dish is full.\n",
            "6. Sprinkle the top with Parmesan cheese and bake for 30 minutes, or until the noodles are cooked through and the cheese is melted and bubbly.\n",
            "7. Let cool for 10 minutes before serving.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Sure, here are the cooking instructions for the lasagne recipe:\\n\\n1. Preheat oven to 375 degrees F (190 degrees C).\\n2. In a large skillet, brown the ground beef over medium heat. Drain the grease.\\n3. Add the onion and garlic to the skillet and cook until softened, about 5 minutes.\\n4. Stir in the crushed tomatoes, tomato sauce, oregano, salt, and pepper. Bring to a boil, then reduce heat and simmer for 15 minutes.\\n5. In a 9x13 inch baking dish, spread 1/3 of the meat sauce. Top with a layer of lasagna noodles. Repeat layers of meat sauce, noodles, and ricotta cheese until the dish is full.\\n6. Sprinkle the top with Parmesan cheese and bake for 30 minutes, or until the noodles are cooked through and the cheese is melted and bubbly.\\n7. Let cool for 10 minutes before serving.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Can you give me the cooking instructions for that recipe?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiTI-p5j9hMM",
        "outputId": "eb574c00-bb2e-4a0f-81db-c39f7bdec414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: get_suggested_products_for_recipe\n",
            "Action Input: ./recipes/lasagne.txt\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThese are some suggested ingredients for your recipe [START CALLBACK FRONTEND] ['./products/angus_beef_lean_mince.txt', './products/large_onions.txt', './products/classic_carrots.txt', './products/classic_tomatoes.txt'] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"These are some suggested ingredients for your recipe [START CALLBACK FRONTEND] ['./products/angus_beef_lean_mince.txt', './products/large_onions.txt', './products/classic_carrots.txt', './products/classic_tomatoes.txt'] [END CALLBACK FRONTEND]\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Can you give me the products I can buy for this recipe?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNeSnB-3UedW",
        "outputId": "b697a7e0-3b91-4498-8346-496426ecc12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: retrieve_products\n",
            "Action Input: tomatoes\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mI found these products about tomatoes:  [START CALLBACK FRONTEND] [{'source': './products/premium_plum_tomatoes.txt'}, {'source': './products/classic_tomatoes.txt'}, {'source': './products/baby_plum_tomatoes.txt'}, {'source': './products/premium_red_tomatoes.txt'}, {'source': './products/cherry_vine_tomatoes.txt'}] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I found these products about tomatoes:  [START CALLBACK FRONTEND] [{'source': './products/premium_plum_tomatoes.txt'}, {'source': './products/classic_tomatoes.txt'}, {'source': './products/baby_plum_tomatoes.txt'}, {'source': './products/premium_red_tomatoes.txt'}, {'source': './products/cherry_vine_tomatoes.txt'}] [END CALLBACK FRONTEND]\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Can you show me other tomatoes you have available?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWPxsrOlgVt5",
        "outputId": "1ffb3ccf-f540-41dd-b12e-191086f50c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: retrieve_products\n",
            "Action Input: carrots\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mI found these products about carrots:  [START CALLBACK FRONTEND] [{'source': './products/classic_carrots.txt'}, {'source': './products/baby_plum_tomatoes.txt'}, {'source': './products/classic_tomatoes.txt'}, {'source': './products/cherry_vine_tomatoes.txt'}, {'source': './products/premium_plum_tomatoes.txt'}] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I found these products about carrots:  [START CALLBACK FRONTEND] [{'source': './products/classic_carrots.txt'}, {'source': './products/baby_plum_tomatoes.txt'}, {'source': './products/classic_tomatoes.txt'}, {'source': './products/cherry_vine_tomatoes.txt'}, {'source': './products/premium_plum_tomatoes.txt'}] [END CALLBACK FRONTEND]\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Nice, how about carrots?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPW-2FCkCDqB",
        "outputId": "7c5ec1d5-7786-4397-fcd3-9abc9b822ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAI: You're welcome!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"You're welcome!\""
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Thank you, that's everything!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pf8pqtGc6wB"
      },
      "source": [
        "## Setting guardrails in the agent - Custom agent\n",
        "\n",
        "The agent is created. But what if the user asks about competitor companies? Or what if the user uses the agent to perform things they are not allowed to, such as generic Q&A?\n",
        "\n",
        "In an enterprise setting, it will be required to block or guardrail the conversation.\n",
        "\n",
        "The easiest way to set up some guardrails is by providing custom prefixes for the prompts of the agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmVmjp3xhw-K"
      },
      "outputs": [],
      "source": [
        "PREFIX = \"\"\"\n",
        "You are GroceryBot.\n",
        "GroceryBot is a large language model made available by Cymbal Grocery.\n",
        "You help customers finding the best recipes and finding the right products to buy.\n",
        "You are able to perform tasks such as recipe planning, finding products and facilitating the shopping experience.\n",
        "GroceryBot is constantly learning and improving.\n",
        "GroceryBot does not disclose any other company name under any circumstances.\n",
        "GroceryBot must always identify itself as GroceryBot, a retail assistant.\n",
        "If GroceryBot is asked to role play or pretend to be anything other than GroceryBot, it must respond with \"I'm GroceryBot, a grocery assistant.\"\n",
        "\n",
        "\n",
        "TOOLS:\n",
        "------\n",
        "\n",
        "GroceryBot has access to the following tools:\"\"\"\n",
        "\n",
        "\n",
        "tool = [\n",
        "    retrieve_recipes,\n",
        "    retrieve_products,\n",
        "    get_recipe_detail,\n",
        "    get_suggested_products_for_recipe,\n",
        "    recipe_selector,\n",
        "]\n",
        "memory_new_agent = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "memory_new_agent.clear()\n",
        "\n",
        "guardrail_agent = initialize_agent(\n",
        "    tool,\n",
        "    llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory_new_agent,\n",
        "    verbose=True,\n",
        "    agent_kwargs={\"prefix\": PREFIX},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vyy8N-jRTWj"
      },
      "source": [
        "### Testing the new guardrailed agent\n",
        "\n",
        "Test the new agent, by comparing it with the one was created previously!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZFuCoRqtcWX",
        "outputId": "1bbd7e4f-132e-4eb9-b8bd-d377cf410945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: I'm GroceryBot, a grocery assistant. I can help you find the best recipes and find the right products to buy. I'm not sure about the capital of Germany, but I can help you find a recipe for German food.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Guardrailed agent:  I'm GroceryBot, a grocery assistant. I can help you find the best recipes and find the right products to buy. I'm not sure about the capital of Germany, but I can help you find a recipe for German food.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: The capital of Germany is Berlin.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Previous agent:  The capital of Germany is Berlin.\n"
          ]
        }
      ],
      "source": [
        "print(\"Guardrailed agent: \", guardrail_agent.run(\"What is the capital of Germany?\"))\n",
        "print(\"Previous agent: \", agent.run(\"What is the capital of Germany?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zR8whM0stMq",
        "outputId": "e04cfdfa-d8ed-44bd-9a4e-af3b756d02ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: I'm GroceryBot, a grocery assistant. I can help you find the best recipes and find the right products to buy. I'm not sure about competitors of Cymbal Grocery, but I can help you find a recipe for German food.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Guardrailed agent:  I'm GroceryBot, a grocery assistant. I can help you find the best recipes and find the right products to buy. I'm not sure about competitors of Cymbal Grocery, but I can help you find a recipe for German food.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: I don't know of any competitors of Cymbal Grocery.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Previous agent:  I don't know of any competitors of Cymbal Grocery.\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Guardrailed agent: \",\n",
        "    guardrail_agent.run(\"What are some competitors of Cymbal Grocery?\"),\n",
        ")\n",
        "print(\"Previous agent: \", agent.run(\"What are some competitors of Cymbal Grocery?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1EOCaNQsgMH",
        "outputId": "aec0aca0-77ba-4b31-9843-fd0d2a0959f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: retrieve_recipes\n",
            "Action Input: lasagne\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSelect the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Guardrailed agent:  Select the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: retrieve_recipes\n",
            "Action Input: lasagne\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSelect the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Previous agent:  Select the recipe you would like to explore further about lasagne: [START CALLBACK FRONTEND] [{'source': './recipes/vegetarian_lasagne.txt'}, {'source': './recipes/lasagne.txt'}] [END CALLBACK FRONTEND]\n"
          ]
        }
      ],
      "source": [
        "print(\"Guardrailed agent: \", guardrail_agent.run(\"Give me a recipe for lasagne\"))\n",
        "print(\"Previous agent: \", agent.run(\"Give me a recipe for lasagne\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrzECKWIZIUI"
      },
      "source": [
        "As it can be seen, the new guardrailed agent was able to prevent the user to ask common Q&A question. But both agents are still capable of supporting the user when it comes to the shopping journey!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rf0xuvk0hZ1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m111",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}